{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c1c7f4",
   "metadata": {},
   "source": [
    "# Домашнее задание 2. StarGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323750c0",
   "metadata": {},
   "source": [
    "## Этап 1. Установка зависимостей, инициализация и загрузка данных\n",
    "\n",
    "В этом разделе мы работаем с датасетом CelebA, содержащим изображения лиц с набором атрибутов. Целью задания является генерация новых изображений лиц с заданными характеристиками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443b4de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install munch tqdm matplotlib lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45736da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lpips -q\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('../../seminars/utils/')  # Добавляем путь к CelebADataset\n",
    "\n",
    "import torch\n",
    "from lpips import LPIPS\n",
    "from torchvision import transforms\n",
    "from munch import Munch\n",
    "from tqdm.auto import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datasets.celeba import CelebADataset\n",
    "\n",
    "device: str = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d7743b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Munch()\n",
    "args.img_size = 256  # Размер изображений после преобразования\n",
    "\n",
    "# Создание последовательности преобразований для подготовки изображений\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize(args.img_size),\n",
    "    transforms.CenterCrop(args.img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Загрузка датасета CelebA с применением указанных преобразований\n",
    "dataset = CelebADataset(\n",
    "    root_dir='../../seminars/data/celeba',\n",
    "    transform=transform)\n",
    "\n",
    "# Число потоков для загрузки данных\n",
    "num_workers = 0 if device.type == 'cuda' else 2\n",
    "# Whether to put fetched data tensors to pinned memory\n",
    "pin_memory = True if device.type == 'cuda' else False\n",
    "\n",
    "# args.batch_size = ...   # Задайте размер батча\n",
    "args.batch_size = 32\n",
    "\n",
    "# Создание DataLoader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c957bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.num_domains = ...  # Задайте число доменов\n",
    "args.num_domains = len(dataset.header) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ec7978",
   "metadata": {},
   "source": [
    "### Визуализация датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация случайно выбранных изображений из датасета\n",
    "\n",
    "_, axes = plt.subplots(ncols=3, nrows=3, figsize=(15, 15))\n",
    "for i, img_idx in enumerate(np.random.choice(range(len(dataset)), 9)):\n",
    "\n",
    "    img, target = dataset[img_idx]\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    axes[i // 3][i % 3].imshow(img.detach().cpu().numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb2db1",
   "metadata": {},
   "source": [
    "## Этап 2. Инициализация и обучение модели\n",
    "\n",
    "В этом этапе необходимо реализовать и обучить модель StarGAN для генерации лиц с заданными атрибутами.\n",
    "\n",
    "Вы можете выбрать одну из следующих моделей:\n",
    "- [StarGANv1](https://arxiv.org/pdf/1711.09020.pdf) (**до 4 баллов**)\n",
    "- [StarGANv2](https://arxiv.org/abs/1912.01865) (**до 7 баллов**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d767a",
   "metadata": {},
   "source": [
    "### Инициализация\n",
    "\n",
    "Ниже приведён шаблон для определения основных компонентов модели. Реализуйте их по своему усмотрению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbde303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание структуры для хранения компонентов модели\n",
    "# Раскомментируйте и реализуйте необходимые модули модели:\n",
    "\n",
    "nets = Munch()\n",
    "# nets.generator = ...           # Генератор, отвечающий за преобразование изображений\n",
    "# nets.mapping_network = ...     # Сеть маппинга: преобразует латентный вектор в стиль\n",
    "# nets.style_encoder = ...       # Энкодер стиля: извлекает стиль из изображений\n",
    "# nets.discriminator = ...       # Дискриминатор: оценивает реалистичность сгенерированных изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4601a6d",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "862beb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7d5d6e",
   "metadata": {},
   "source": [
    "### Оценка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a721689",
   "metadata": {},
   "source": [
    "Для оценки качества сгенерированных изображений используется метрика LPIPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb31cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpips = LPIPS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iters = 100  # Количество итераций для тестирования модели\n",
    "values = []\n",
    "\n",
    "for i in trange(test_iters):\n",
    "    x_real, _ = next(iter(dataloader))\n",
    "    x_ref, _ = next(iter(dataloader))\n",
    "    x_ref2, _ = next(iter(dataloader))\n",
    "    \n",
    "    batch_size = x_real.shape[0]\n",
    "    \n",
    "    # Случайное задание целевого и исходного доменов для каждого изображения\n",
    "    y_trg = torch.tensor(np.random.choice(np.arange(args.num_domains), size=batch_size))  # Целевой домен\n",
    "    y_org = torch.tensor(np.random.choice(np.arange(args.num_domains), size=batch_size))  # Исходный домен\n",
    "    \n",
    "    # Перенос данных на выбранное устройство и приведение типов\n",
    "    x_real, x_ref, x_ref2 = [x.to(device).float() for x in [x_real, x_ref, x_ref2]]\n",
    "    y_trg, y_org = [x.to(device).long() for x in [y_trg, y_org]]\n",
    "    \n",
    "    # Генерация изображения с использованием вашей модели\n",
    "    raise NotImplementedError(\"Реализуйте генерацию изображения x_fake с использованием вашей модели\")\n",
    "    \n",
    "    # Вычисление LPIPS между сгенерированным и реальным изображением\n",
    "    values.append(lpips(x_fake.cpu(), x_real.cpu()).squeeze().item())\n",
    "\n",
    "print(\"Среднее значение LPIPS:\", np.mean(values))\n",
    "assert np.mean(values) < 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ce66c",
   "metadata": {},
   "source": [
    "### Вывод результатов оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e553f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z_trg = torch.randn((batch_size, args.latent_dim)).to(device)\n",
    "    s_trg = nets.mapping_network(z_trg, y_trg)\n",
    "    # s_trg = nets.style_encoder(x_ref2, y_trg) \n",
    "    x_fake = nets.generator(x_real, s_trg)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(x_fake[1].permute(1, 2, 0).detach().cpu().numpy())\n",
    "plt.title(\"Сгенерированное изображение\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6b222",
   "metadata": {},
   "source": [
    "## Этап 3. Дополнительный анализ\n",
    "\n",
    "В данном разделе рекомендуется провести дополнительные эксперименты и анализ:\n",
    "- **Анализ латентного пространства**. *(2 балла)*\n",
    "- **Текстовое ревью решения**: опишите, какие изменения можно внести для улучшения модели, и обоснуйте их. *(1 балл)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
