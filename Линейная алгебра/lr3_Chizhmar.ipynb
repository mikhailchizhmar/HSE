{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loyHNyXiknh2"
   },
   "source": [
    "## Начало численной лин алгебры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEyHZegfknh5"
   },
   "source": [
    "### Нахождение наибольшего собственного значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPhFc9W8knh5"
   },
   "source": [
    "В этом разделе мы рассмотрим некоторые методы, которые могут быть использованы для приближенного вычисления собственных значений матрицы A. Хотя для небольших матриц возможно найти точные собственные значения, этот подход оказывается нереалистичным для больших матриц.\n",
    "\n",
    "Во многих вводных учебниках приводится прямой способ вычисления собственных значений квадратной матрицы A размером n × n путем нахождения корней связанного n-го степенного полинома, известного как характеристический полином. Например, предположим, что A - матрица размером 2 × 2.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[ \\begin{array}{rr} a & b  \\\\ c & d \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Собственные значения A являются решениями квадратного уравнения $\\lambda^2 - (a+d)\\lambda + ad-bc = 0$, которое может быть явно записано через a, b, c и d с использованием формулы дискреминанта. Проблема с большими матрицами заключается в том, что полином будет высокой степени, и корни не могут быть легко найдены по формуле.\n",
    "\n",
    "Алгоритмы, которые мы рассматриваем в этом разделе, являются итерационными методами. Они генерируют последовательность векторов $\\{X^{(1)}, X^{(2)}, X^{(3)}, ... \\}$, которые приближаются к истинному собственному вектору матрицы. Приближенное значение соответствующего собственного значения может быть вычислено путем умножения приближенного собственного вектора на матрицу A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUIN8_xRknh6"
   },
   "source": [
    "### Метод степеней\n",
    "\n",
    "Метод генерирует последовательность векторов путем многократного умножения на матрицу. При выполнении определенных условий последовательность векторов приближается к собственному вектору, соответствующему собственному значению, которое имеет наибольшую абсолютную величину.\n",
    "\n",
    "Для простейшего объяснения предположим, что A - матрица размером n × n, диагонализуемая с собственными векторами $\\{V_1, V_2, ... V_n\\}$, и $\\lambda_1$ - собственное значение A с наибольшей по модулю величиной. Для начала работы метода степеней мы выбираем любой ненулевой вектор и обозначаем его $X^{(0)}$. Мы можем выразить $X^{(0)}$ как линейную комбинацию собственных векторов, так как они образуют базис в $\\mathbb{R}^n$.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X^{(0)} = c_1V_1 + c_2V_2 + ... c_nV_n\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Затем мы формируем последовательность векторов $X^{(1)}$, $X^{(2)}$, $X^{(3)}$, ..., задавая $X^{(m)}= AX^{(m-1)}$. Каждый из этих векторов также может быть выражен через собственные векторы:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "X^{(1)} = AX^{(0)} & = c_1AV_1 + c_2AV_2 + ... c_nAV_n \\\\\n",
    "                   & = c_1\\lambda_1V_1 + c_2\\lambda_2V_2 + ... c_n\\lambda_nV_n \\\\\n",
    "X^{(2)} = AX^{(1)} & = c_1\\lambda_1AV_1 + c_2\\lambda_2AV_2 + ... c_n\\lambda_nAV_n \\\\\n",
    "                   & = c_1\\lambda_1^2V_1 + c_2\\lambda_2^2V_2 + ... c_n\\lambda_n^2V_n \\\\\n",
    "                   & \\vdots \\\\\n",
    "X^{(m)} = AX^{(m-1)} & = c_1\\lambda_1^{m-1}AV_1 + c_2\\lambda_2^{m-1}AV_2 + ... c_n\\lambda_n^{m-1}AV_n \\\\\n",
    "                   & = c_1\\lambda_1^mV_1 + c_2\\lambda_2^mV_2 + ... c_n\\lambda_n^mV_n\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Затем в выражении для $X^{(m)}$ мы можем вынести множитель $\\lambda_1^m$, чтобы понять, что происходит, когда $m$ становится большим.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "X^{(m)} =  \\lambda_1^m\\left(c_1V_1 + c_2\\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^mV_2 + ... c_n\\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^mV_n\\right)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Если $|\\lambda_1| > |\\lambda_i|$ для всех $i\\neq 1$, то $|\\lambda_i/\\lambda_1|< 1$ и $(\\lambda_i/\\lambda_1)^m$ будет стремиться к нулю, когда $m$ становится большим. Это означает, что если мы многократно умножаем вектор на матрицу $A$, то в конечном итоге мы получим вектор, близкий по направлению к собственному вектору, соответствующему $\\lambda_1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsjUMSHpknh8"
   },
   "source": [
    "Давайте продемонстрируем вычисление на данной здесь матрице, прежде чем обсудим метод далее.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A = \\left[ \\begin{array}{rrrr} -2 & 6 & 2 & -8 \\\\ -6 & 0 & 12 & 12 \\\\ -6 & 0 & 12 & 12 \\\\ -10 & 3 & 7 & 14 \\end{array}\\right]\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Для практической целесообразности обычно масштабируют векторы в последовательности до единичной длины при применении метода степеней. Если векторы в последовательности не масштабируют, их величины будут увеличиваться, если $\\lambda_1>1$, или убывать, если $\\lambda_1<1$. Поскольку все компоненты векторов делятся на один и тот же коэффициент при масштабировании вектора, этот шаг не изменяет конечное поведение последовательности. Масштабированная последовательность векторов все равно приближается к направлению собственного вектора.\n",
    "\n",
    "Мы выбираем произвольный $X^{(0)}$ и вычисляем $X^{(20)}$ с использованием следующего правила.\n",
    "$$\n",
    "\\begin{equation}\n",
    "X^{(m)}=\\frac{AX^{(m-1)}}{||AX^{(m-1)}||}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Eg15vYzIknh9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HoinoSsVknh9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[-2, 6, 2, -8],\n",
    "              [-6, 0, 12, 12],\n",
    "              [-6, 0, 12, 12],\n",
    "              [-10, 3, 7, 14]])\n",
    "X = np.array([1, 0, 0, 0])[:, None]\n",
    "\n",
    "for _ in range(20):\n",
    "    X = (A @ X) / linalg.norm(A @ X)\n",
    "\n",
    "ans = np.array([\n",
    "    [ 1.57532321e-12],\n",
    "    [-5.77350269e-01],\n",
    "    [-5.77350269e-01],\n",
    "    [-5.77350269e-01]])\n",
    "np.isclose(X, ans).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DU1_QU-knh9"
   },
   "source": [
    "Если $X$ - собственный вектор матрицы A с единичной длиной, то $|AX| = |\\lambda_1X| = |\\lambda_1|$.  Значит мы аппроксимируем собственное значение $|\\lambda_1|$ с помощью $|AX|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l-gpiqRVknh-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.000000000020005"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linalg.norm(A @ X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vUG2Hz0kniA"
   },
   "source": [
    "Похоже, что 24 - это приближенная оценка для $\\lambda_1$. Чтобы убедиться в правильности наших расчетов, мы можем сравнить $AX$ c $\\lambda_1X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BOdANuEWkniB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.09561274e-11],\n",
       "       [-9.45021839e-12],\n",
       "       [-9.45021839e-12],\n",
       "       [-1.57509561e-11]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A@X - 24*X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CweEzFtmkniB"
   },
   "source": [
    "Действительно, разность $AX−24X$ небольшая. Заметим, что в этом случае мы можем даже выполнить вычисления с использованием целочисленного умножения. Обратите внимание, что у $X$ первый элемент равен 0, а остальные элементы равны между собой. Если мы установим эти элементы в 1, результат легко вычислить даже без использования компьютера. (Помните, что мы можем изменить масштаб собственного вектора, и он все равно останется собственным вектором.)\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "AX = \\left[ \\begin{array}{rrrr} -2 & 6 & 2 & -8 \\\\ -6 & 0 & 12 & 12 \\\\ -6 & 0 & 12 & 12 \\\\ -10 & 3 & 7 & 14 \\end{array}\\right]\n",
    "\\left[ \\begin{array}{r} 0 \\\\ 1\\\\ 1 \\\\ 1 \\end{array}\\right] =\n",
    "\\left[ \\begin{array}{r} 0 \\\\ 24\\\\ 24 \\\\ 24 \\end{array}\\right] = 24X\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-te9fJ0kniB"
   },
   "source": [
    "На практике нам часто неизвестно, сколько итераций потребуется для получения хорошего приближения собственного вектора. Вместо этого мы должны указать условие, при котором мы будем удовлетворены приближением, и завершить итерацию.  \n",
    "Например, $||AX^{(m)}||\\approx \\lambda_1$ и $AX^{(m)}\\approx \\lambda_1X^{(m)}$ мы можем требовать $AX^{(m)} - ||AX^{(m)}||X^{(m)} < \\epsilon$ для маленьких чисел $\\epsilon$.  Это условие гарантирует, что $X_{(m)}$ ведет себя примерно как собственный вектор. Также лучше включить в код ограничение на количество итераций. Это гарантирует, что вычисление в конечном итоге завершится, даже если удовлетворительный результат еще не достигнут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3DNvEX-ykniC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvector is approximately:\n",
      "[[ 1.65181395e-06]\n",
      " [-5.77350269e-01]\n",
      " [-5.77350269e-01]\n",
      " [-5.77350269e-01]] \n",
      "\n",
      "Magnitude of the eigenvalue is approximately:\n",
      "24.000020980823063 \n",
      "\n",
      "Magnitude of the difference is:\n",
      "4.328470441185797e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TOLERANCE = 1e-4\n",
    "MAX_ITERATIONS = 100\n",
    "\n",
    "iter = 0\n",
    "X = np.array([1, 0, 0, 0])[:, None] # начальное приближение (какое-то)\n",
    "Y = A @ X\n",
    "difference = Y - linalg.norm(Y)*X\n",
    "while (iter < MAX_ITERATIONS and linalg.norm(difference) > TOLERANCE):\n",
    "    X = Y / linalg.norm(Y)\n",
    "    Y = A@X\n",
    "    difference = Y - linalg.norm(Y) * X\n",
    "    iter += 1\n",
    "\n",
    "print(\"Eigenvector is approximately:\")\n",
    "print(X,'\\n')\n",
    "print(\"Magnitude of the eigenvalue is approximately:\")\n",
    "print(linalg.norm(Y),'\\n')\n",
    "print(\"Magnitude of the difference is:\")\n",
    "print(linalg.norm(difference))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wW3hTwY0kniC"
   },
   "source": [
    "На практике более распространенным условием является требование $||X^{(m)} - X^{(m-1})|| < \\epsilon$ для заданного $\\epsilon$. Это условие требует лишь того, чтобы векторы в последовательности становились ближе друг к другу, а не обязательно приближались к собственному вектору."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jswfAxVBkniC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvector is approximately:\n",
      "[[ 2.64294012e-05]\n",
      " [-5.77350269e-01]\n",
      " [-5.77350269e-01]\n",
      " [-5.77350269e-01]] \n",
      "\n",
      "Magnitude of the eigenvalue is approximately:\n",
      "24.000122026538186 \n",
      "\n",
      "Magnitude of the difference is:\n",
      "4.328470441185797e-05\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1, 0, 0, 0])[:, None]\n",
    "TOLERANCE = 1e-4\n",
    "MAX_ITERATIONS = 100\n",
    "\n",
    "#перепишите код выше с условием на разницу норм векторов X_m и X_{m-1}\n",
    "iter = 0\n",
    "prev_X = np.zeros_like(X)\n",
    "while iter < MAX_ITERATIONS and linalg.norm(X - prev_X) > TOLERANCE:\n",
    "    prev_X = X\n",
    "    Y = A @ X\n",
    "    X = Y / linalg.norm(Y)\n",
    "    iter += 1\n",
    "\n",
    "print(\"Eigenvector is approximately:\")\n",
    "print(X,'\\n')\n",
    "print(\"Magnitude of the eigenvalue is approximately:\")\n",
    "print(linalg.norm(Y),'\\n')\n",
    "print(\"Magnitude of the difference is:\")\n",
    "print(linalg.norm(difference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Mb6XIy8kniC"
   },
   "source": [
    "### Метод степеней: преимущества и недостатки\n",
    "\n",
    "Хотя метод степеней легко понять и применить, у него есть недостатки. Самый очевидный недостаток заключается в том, что метод применим только к наибольшему собственному значению. Это не является серьезным недостатком, поскольку в большинстве приложений требуется лишь приближенное значение наибольшего собственного значения. Однако можно легко модифицировать метод для приближенного вычисления других собственных значений.\n",
    "\n",
    "Более существенным недостатком является медленная сходимость последовательности в некоторых случаях. Например, мы можем наблюдать, если $|\\lambda_1|$ близко к $|\\lambda_2|$, тогда $|\\lambda_1/\\lambda_2|^m$ стремиться к нулю медленно.  Степенной метод может несойтись, если $|\\lambda_1| = |\\lambda_2|$, то есть когда $\\lambda_1 = -\\lambda_2$, или когда $\\lambda_1$ и $\\lambda_2$ комплексно сопряженная пара.  Плюс начальное приближение $X_0$ не должен иметь координаты сильно близкие к нулю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48gQmXMOkniC"
   },
   "source": [
    "**Задание 1:** Напишите функцию для поиска наибольшего собственного значения по модулю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZVV7O2DMkniE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def largest_eigen_value(matrix: np.ndarray, tolerance: float=1e-4, max_iter: int=100) -> tuple:\n",
    "    X = np.random.rand(matrix.shape[0], 1)\n",
    "    X /= linalg.norm(X)\n",
    "\n",
    "    iter = 0\n",
    "    prev_X = np.zeros_like(X)\n",
    "    while iter < max_iter and linalg.norm(X - prev_X) > tolerance:\n",
    "        prev_X = X\n",
    "        Y = matrix @ X\n",
    "        X = Y / linalg.norm(Y)\n",
    "        iter += 1\n",
    "\n",
    "    eigenvalue = (X.T @ matrix @ X / (X.T @ X))[0][0]\n",
    "\n",
    "    return eigenvalue, X\n",
    "\n",
    "A = np.array([[9,-1,-3],[0,6,0],[-6,3,6]])\n",
    "largest_e_val, _ = largest_eigen_value(A)\n",
    "np.isclose(largest_e_val, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfNJlSpQkniE"
   },
   "source": [
    "## Стохастические матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxBH5jWHkniE"
   },
   "source": [
    "Стохастическая матрица – это квадратная матрица, элементы которой являются неотрицательными и такими, что сумма элементов каждой строки/столбца равна единице. Эта особенность делает стохастические матрицы ключевыми в теории вероятностей и марковских процессах. Матрица $P$ размерности $n \\times n$ считается стохастической, если выполняется условие:\n",
    "\n",
    "$\n",
    "\\sum_{j=1}^{n} P_{ij} = 1 \\quad \\text{для } i = 1, 2, \\ldots, n\n",
    "$\n",
    "\n",
    "где $P_{ij}$ - элемент матрицы в i-й строке и j-м столбце. Эта характеристика связана с вероятностной интерпретацией: элемент $P_{ij}$ может рассматриваться как вероятность перехода из состояния $i$ в состояние $j$ в марковском процессе. Такие матрицы широко применяются в моделировании случайных процессов и анализе систем, где случайные переходы между состояниями играют важную роль."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4x5zKAE6kniE"
   },
   "source": [
    "Дальше нам понадобятся два факта о стохастических матрицах (в подпунктах представлено их доказательно, но оно нам не понадобиться в дальнейшем)\n",
    "\n",
    "- 1 является собственным значением для любой стохастической матрицы\n",
    "    - проверьте, что у $A$ и у $A^T$ одинаковые собственные значения\n",
    "    - проверьте является ли вектор из всех единиц собственным вектором для собственного значения 1\n",
    "\n",
    "- для любого собственного значения стохастической матрицы $\\lambda$ выполнено $|\\lambda| \\leq 1$\n",
    "    - Предположим, что $Ax = \\lambda x$ для некоторого $\\lambda > 1$. Поскольку строки матрицы $A$ неотрицательны и суммируются до 1, каждый элемент вектора $Ax$ представляет собой выпуклую комбинацию компонентов вектора $x$, которая не может быть больше, чем $x_{\\text{max}}$, наибольшая компонента вектора $x$. С другой стороны, по меньшей мере один элемент $\\lambda x$ больше $x_{\\text{max}}$, что доказывает, что $\\lambda > 1$ невозможно. В итоге данное утверждение демонстрирует, что если $Ax = \\lambda x$ для некоторого $\\lambda > 1$, то это приводит к противоречию, поскольку компоненты $\\lambda x$ не могут превышать максимальную компоненту $x$. Следовательно, предположение $\\lambda > 1$ доказано невозможным.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FVthFnMkniF"
   },
   "source": [
    "## PageRank\n",
    "\n",
    "PageRank (разработанный Ларри Пейджем и Сергеем Брином) произвел революцию в веб-поиске, создав ранжированный список веб-страниц на основе базовых возможностей подключения к Интернету. Алгоритм PageRank основан на идеальном случайном веб-серфере, который, зайдя на страницу, переходит на следующую страницу, нажав на ссылку. Пользователь имеет равную вероятность перейти по любой ссылке на странице и, перейдя на страницу без ссылок, имеет равную вероятность перейти на любую другую страницу, введя ее URL. Кроме того, пользователь может иногда выбрать ввод случайного URL-адреса вместо перехода по ссылкам на странице. PageRank - это ранжированный порядок страниц от наиболее вероятной до наименее вероятной страницы, которую будет просматривать пользователь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOLMdSxakniF"
   },
   "source": [
    "## PageRank как задача линейной алгебры\n",
    "\n",
    "Давайте представим микроинтернет, содержащий всего 6 веб-сайтов (Avocado, Bullseye, Cat Babel, Dromeda, eTings, and FaceSpace). Каждый веб-сайт ссылается на некоторые другие, и это формирует сеть, как показано на рисунке,\n",
    "\n",
    "![image info](./internet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpVkESRGkniF"
   },
   "source": [
    "Принцип разработки PageRank заключается в том, что на важные веб-сайты будут ссылаться другие важные веб-сайты. Этот рекурсивный принцип ляжет в основу нашего мышления.\n",
    "\n",
    "Представьте, что в нашем микроинтернете есть 100 прокрастинирующих пользователей, каждый из которых одновременно просматривает один веб-сайт. Каждую минуту пользователи переходят по ссылке на своем веб-сайте на другой сайт в микроинтернете. Через некоторое время на веб-сайты, на которые больше всего ссылок, будет заходить больше посетителей, и в долгосрочной перспективе каждую минуту на каждый посетитель, покидающий веб-сайт, будет заходить другой, сохраняя общее количество посетителей на каждом веб-сайте постоянным. PageRank - это просто ранжирование веб-сайтов по количеству размещенных на них частей в конце этого процесса.\n",
    "\n",
    "Мы представляем количество просмотров на каждом веб-сайте с помощью вектора,\n",
    "$$\\mathbf{r} = \\begin{bmatrix} r_A \\\\ r_B \\\\ r_C \\\\ r_D \\\\ r_E \\\\ r_F \\end{bmatrix}$$\n",
    "\n",
    "И скажем, что количество путей на каждом веб-сайте в минуту $i+1$ связано с количеством путей в минуту $i$ с помощью матричного преобразования\n",
    "\n",
    "$$ \\mathbf{r}^{(i+1)} = L \\,\\mathbf{r}^{(i)}$$\n",
    "с матрицей $L$ следующего вида\n",
    "$$ L = \\begin{bmatrix}\n",
    "L_{A→A} & L_{B→A} & L_{C→A} & L_{D→A} & L_{E→A} & L_{F→A} \\\\\n",
    "L_{A→B} & L_{B→B} & L_{C→B} & L_{D→B} & L_{E→B} & L_{F→B} \\\\\n",
    "L_{A→C} & L_{B→C} & L_{C→C} & L_{D→C} & L_{E→C} & L_{F→C} \\\\\n",
    "L_{A→D} & L_{B→D} & L_{C→D} & L_{D→D} & L_{E→D} & L_{F→D} \\\\\n",
    "L_{A→E} & L_{B→E} & L_{C→E} & L_{D→E} & L_{E→E} & L_{F→E} \\\\\n",
    "L_{A→F} & L_{B→F} & L_{C→F} & L_{D→F} & L_{E→F} & L_{F→F} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "где столбцы представляют вероятность перехода с веб-сайта на любой другой веб-сайт и суммируются в единицу.\n",
    "Строки определяют, насколько вероятно, что вы перейдете на веб-сайт с любого другого веб-сайта, их величины необязательно суммируются в единицу.\n",
    "Длительное поведение этой системы сводится к условию $ \\mathbf{r}^{(i+1)} = \\mathbf{r}^{(i)}$, можно опустить индексы и переписать это так:\n",
    "$$ L \\,\\mathbf{r} = \\mathbf{r}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YdpFY9yKkniF"
   },
   "outputs": [],
   "source": [
    "# Замените символы ... на вероятность перейти из сайта FaceSpace в другие\n",
    "L = np.array([[0,   1/2, 1/3, 0, 0,   0],\n",
    "              [1/3, 0,   0,   0, 1/2, 0],\n",
    "              [1/3, 1/2, 0,   1, 0,   1/2],\n",
    "              [1/3, 0,   1/3, 0, 1/2, 1/2],\n",
    "              [0,   0,   0,   0, 0,   0],\n",
    "              [0,   0,   1/3, 0, 0,   0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSfJPl9qkniG"
   },
   "source": [
    "В принципе, мы могли бы использовать библиотеку линейной алгебры, как показано ниже, для вычисления собственных значений и векторов. И это сработало бы для небольшой системы. Но это становится невозможным для больших систем. И поскольку мы заботимся только о главном собственном векторе (том, который имеет наибольшее собственное значение, которое в данном случае будет равно 1), мы можем использовать степенной метод, который будет лучше масштабироваться и быстрее для больших систем.\n",
    "\n",
    "Используйте приведенный ниже код, чтобы просмотреть PageRank для этого микроинтернета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6-_wz0SfkniG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.        ,  5.33333333, 40.        , 25.33333333,  0.        ,\n",
       "       13.33333333])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eVals, eVecs = linalg.eig(L) # получить собс. значения и собс. вектора\n",
    "order = np.absolute(eVals).argsort()[::-1] # отсортируем их по абс. значениям\n",
    "eVals = eVals[order]\n",
    "eVecs = eVecs[:,order]\n",
    "\n",
    "r = eVecs[:, 0] # пусть r это вектор соответствующий максимальному собственному значению\n",
    "100 * np.real(r / np.sum(r)) # нормируем вектор, чтобы суммировался в 1, затем умножим на 100 прокрастинирующих пользователей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLrRic43kniG"
   },
   "source": [
    "Из этого списка мы можем видеть количество прокрастинирующих пользователей, которые мы ожидаем найти на каждом веб-сайте через долгое время. Расположив их в порядке популярности (на основе этого показателя), PageRank этого микроинтернет составляет:\n",
    "\n",
    "CatBabel, Dromeda, Avocado, FaceSpace, Bullseye, eTings\n",
    "\n",
    "Возвращаясь к диаграмме микроинтернет, этого ли вы ожидали? Убедите себя, что на основе того, какие страницы кажутся важными, учитывая, какие другие ссылаются на них, это разумный рейтинг."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tVIp5DjkniG"
   },
   "source": [
    "Примените степенной метод для матрицы $L$ и сравните полученный результат с результатом выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "g5ES8NOrkniG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_val, e_vec = largest_eigen_value(L)\n",
    "np.isclose(e_vec / linalg.norm(e_vec), r[:, None] / linalg.norm(r[:, None]), rtol=1e-3).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulvg-BG4kniG"
   },
   "source": [
    "### Параметр затухания\n",
    "\n",
    "Система, которую мы только что рассмотрели, сходилась достаточно быстро к правильному ответу.\n",
    "Рассмотрим расширение нашего микро-интернета, где начинаются проблемы.\n",
    "\n",
    "Предположим, что в микро-интернет добавлен новый сайт: Веб-сайт *Geoff*.\n",
    "Этот сайт связан с *FaceSpace* и ссылается только на себя.\n",
    "\n",
    "\n",
    "![Расширенный микро-интернет](./internet2.png \"Расширенный микро-интернет\")\n",
    "\n",
    "\n",
    "Интуитивно понятно, что только *FaceSpace*, находящийся в нижней половине рейтинга страниц, ссылается на этот сайт среди двух других, поэтому мы можем ожидать, что у *Geoff* будет соответственно низкий рейтинг PageRank.\n",
    "\n",
    "Постройте новую матрицу $L$ для расширенного микро-интернета и используйте степенной метод. Посмотрим, что произойдет..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uC6d06DzkniG"
   },
   "outputs": [],
   "source": [
    "# будем использовать переменную L2 для матрицы нового интернета\n",
    "L2 = np.array([[0,   1/2, 1/3, 0, 0,   0, 0 ],\n",
    "               [1/3, 0,   0,   0, 1/2, 0, 0 ],\n",
    "               [1/3, 1/2, 0,   1, 0,   0, 0 ],\n",
    "               [1/3, 0,   1/3, 0, 1/2, 0, 0 ],\n",
    "               [0,   0,   0,   0, 0,   0, 0 ],\n",
    "               [0,   0,   1/3, 0, 0,   1, 0 ],\n",
    "               [0,   0,   0,   0, 0,   0, 1 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WHmldsuVkniG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.12103714e-04],\n",
       "       [8.27453483e-05],\n",
       "       [4.19574029e-04],\n",
       "       [2.46428467e-04],\n",
       "       [0.00000000e+00],\n",
       "       [9.91404440e-01],\n",
       "       [1.30831751e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_val, e_vec = largest_eigen_value(L2)\n",
    "e_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzH4ObOqkniI"
   },
   "source": [
    "### Параметр затухания\n",
    "\n",
    "Это не так хорошо! *Geoff* кажется привлекающим всё внимание в микро-интернете и, кажется, находится в верхней части рейтинга PageRank.\n",
    "Это поведение можно понять, потому что, когда пользователь попадает на веб-сайт *Geoff*, он не может покинуть его, так как все ссылки ведут обратно к *Geoff*.\n",
    "\n",
    "Чтобы справиться с этим, мы можем добавить небольшую вероятность того, что пользователь не будут следовать по ссылке на веб-странице, а вместо этого посетят веб-сайт на микро-интернете случайным образом.\n",
    "Мы скажем, что вероятность того, что они перейдут по ссылке, равна $d$, и вероятность выбора случайного веб-сайта равна, следовательно, $1-d$.\n",
    "Мы можем использовать новую матрицу, чтобы определить, на какие веб-сайты посещают пользователи каждую минуту.\n",
    "$$ M = d \\, L + \\frac{1-d}{n} \\, J $$\n",
    "где $J$ - это матрица размером $n\\times n$, в которой каждый элемент равен единице.\n",
    "\n",
    "Если $d$ равно единице, у нас есть тот случай, который у нас был ранее, тогда как если $d$ равно нулю, мы всегда будем посещать случайную веб-страницу, и, следовательно, все веб-страницы будут равновероятными и равнозначными.\n",
    "\n",
    "Чтобы эта модификация работала лучше всего, $1-d$ должно быть довольно маленьким, хотя мы не будем обсуждать, насколько именно маленьким. Давайте попробуем этот метод PageRank с этим расширением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FtD_kUvykniI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27525338],\n",
       "       [0.20009713],\n",
       "       [0.44817464],\n",
       "       [0.30467107],\n",
       "       [0.10064549],\n",
       "       [0.68390003],\n",
       "       [0.33565307]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 0.7 # можете поиграть с этим параметром\n",
    "M = d * L2 + (1 - d) / L2.shape[0] * np.ones_like(L2)\n",
    "e_val, e_vec = largest_eigen_value(M)\n",
    "e_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6v1M7X3skniI"
   },
   "source": [
    "### Параметр затухания\n",
    "\n",
    "Это, конечно, лучше. PageRank предоставляет разумные значения пользователей, которые оказываются на каждой веб-странице.\n",
    "Тем не менее этот метод все еще предсказывает, что у Джеффа есть высокий рейтинг веб-страницы.\n",
    "Это можно рассматривать как следствие использования небольшой сети. Мы также можем обойти эту проблему, не учитывая ссылки на себя при создании матрицы $L$ (и если у веб-сайта нет исходящих ссылок, сделать его равномерно связанным со всеми веб-сайтами).\n",
    "Мы не будем идти дальше по этому пути, поскольку это уже относится к улучшениям PageRank, а не к собственным задачам.\n",
    "\n",
    "Теперь у вас есть хорошие знания о PageRank, и вы можете написать свой код для вычисления PageRank веб-сайта с тысячами записей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dhVWijAakniI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8, 1, 5, 2, 3, 7, 4, 9, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_pagerank(adj_matrix, dampler=0.8):\n",
    "    \"\"\"\n",
    "    adj_matrix - матрица связи графа (1 если свзяь есть, 0 если связи нет)\n",
    "    dampler - параметр затухания\n",
    "\n",
    "    return:\n",
    "        pagerank вектор, показывающий важность сайта\n",
    "    \"\"\"\n",
    "    n = adj_matrix.shape[0]\n",
    "    L = adj_matrix.copy().astype(np.float64)\n",
    "    column_sums = L.sum(axis=0)\n",
    "    column_sums[column_sums == 0] = 1\n",
    "    L /= column_sums\n",
    "\n",
    "    J = np.ones((n, n))\n",
    "    M = dampler * L + (1 - dampler) / n * J\n",
    "    _, e_vec = largest_eigen_value(M)\n",
    "    return e_vec\n",
    "\n",
    "\n",
    "test_internet = np.array([\n",
    "    [0, 1, 1, 0, 1, 1, 1, 0, 1, 1],\n",
    "    [1, 0, 0, 0, 1, 1, 0, 0, 1, 1],\n",
    "    [1, 1, 0, 1, 1, 1, 0, 0, 1, 0],\n",
    "    [1, 1, 1, 0, 1, 0, 0, 1, 1, 0],\n",
    "    [1, 0, 1, 0, 1, 1, 1, 0, 1, 0],\n",
    "    [0, 1, 1, 1, 0, 0, 0, 0, 1, 1],\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
    "    [1, 1, 0, 1, 1, 0, 0, 1, 1, 0],\n",
    "    [0, 1, 0, 0, 0, 1, 0, 1, 0, 1],\n",
    "    [1, 1, 0, 1, 1, 1, 0, 1, 0, 0]])\n",
    "\n",
    "e_vec = calc_pagerank(test_internet)\n",
    "sorted_internet = np.arange(len(test_internet))[np.argsort(e_vec.flatten())]\n",
    "sorted_internet"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
